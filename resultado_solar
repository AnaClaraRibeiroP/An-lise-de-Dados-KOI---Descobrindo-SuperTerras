import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import LabelEncoder
from sklearn.calibration import CalibratedClassifierCV

# Carregar o arquivo CSV
file_path = r'c:\Users\aclarari\Desktop\23-04-2024\TABELAS\cumulative.csv'
df = pd.read_csv(file_path, usecols=[
    'kepid',
    'koi_disposition', #Disposição no Arquivo de Exoplanetas - Confirmação de exoplaneta (CONFIRMED), falso positivo (FALSE POSITIVE), ou candidato (CANDIDATE)
    "koi_steff",  # Temperatura Efetiva Estelar [K]
    "koi_slogg",  # Gravidade Superficial Estelar [log10(cm/s²)]
    "koi_smet",  # Metalicidade Estelar [dex]
    "koi_srad",  # Raio Estelar [raios solares]
    "koi_smass",  # Massa Estelar [massas solares]
    "koi_sage",  # Idade Estelar [Gyr]
])

# Converter 'koi_disposition' para labels numéricas
label_encoder = LabelEncoder()
df['koi_disposition'] = label_encoder.fit_transform(df['koi_disposition'])

# Lidar com valores nulos
df.fillna(0, inplace=True)

# Remover colunas não numéricas
non_numeric_columns = df.select_dtypes(include=['object']).columns
df = df.drop(non_numeric_columns, axis=1)

# Dividir os dados em recursos (X) e rótulos (y)
X = df.drop(['koi_disposition'], axis=1)
y = df['koi_disposition']

# Dividir os dados em conjuntos de treinamento e teste
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Inicializar e treinar o modelo Random Forest
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)

# Obter importâncias das features
feature_importances = rf_model.feature_importances_

# Mapear importâncias para nomes das colunas
feature_importance_dict = dict(zip(X.columns, feature_importances))

# Imprimir as principais colunas e suas importâncias
print("\nPrincipais colunas e suas importâncias:")
for feature, importance in sorted(feature_importance_dict.items(), key=lambda x: x[1], reverse=True)[:10]:
    print(f"{feature}: {importance}")

# Calibrar o modelo para obter as probabilidades
calibrated_model = CalibratedClassifierCV(rf_model, method='sigmoid', cv='prefit')
calibrated_model.fit(X_train, y_train)

# Obter as probabilidades no conjunto de teste
probabilities = calibrated_model.predict_proba(X_test)

# Extraindo a probabilidade para a classe 'CANDIDATE'
candidate_probabilities = probabilities[:, label_encoder.transform(['CANDIDATE'])[0]]

# Adicionando as probabilidades ao DataFrame original apenas para candidatos
df['candidate_probability'] = calibrated_model.predict_proba(X)[:, label_encoder.transform(['CANDIDATE'])[0]]

# Defina um limiar para decidir entre "confirmed" e "false positive"
limiar = 0.95

# Adiciona uma coluna ao DataFrame indicando se é "confirmed" ou "false positive" apenas para candidatos
df.loc[df['koi_disposition'] == label_encoder.transform(['CANDIDATE'])[0], 'new_disposition'] = ['NEW CONFIRMED' if prob >= limiar else 'NEW FALSE POSITIVE' for prob in df.loc[df['koi_disposition'] == label_encoder.transform(['CANDIDATE'])[0], 'candidate_probability']]

# Mantém os valores originais de 'confirmed' e 'false positive' na nova coluna para as demais instâncias
df.loc[df['koi_disposition'] != label_encoder.transform(['CANDIDATE'])[0], 'new_disposition'] = df.loc[df['koi_disposition'] != label_encoder.transform(['CANDIDATE'])[0], 'koi_disposition']


# Selecionar os top 10 candidatos com as maiores probabilidades
top_10_candidates = df[df['koi_disposition'] == label_encoder.transform(['CANDIDATE'])[0]].nlargest(10, 'candidate_probability')

# Exibir os top 10 candidatos
print('\nTop 10 Candidatos:')
print(top_10_candidates[['kepid', 'koi_disposition', 'candidate_probability']])

# Salvar os resultados em um arquivo CSV
output_file_path = r'c:\Users\aclarari\Desktop\23-04-2024\TABELAS\resultado_solar.csv'
df.to_csv(output_file_path, index=False)
print(f'\nResultados salvos em {output_file_path}')




